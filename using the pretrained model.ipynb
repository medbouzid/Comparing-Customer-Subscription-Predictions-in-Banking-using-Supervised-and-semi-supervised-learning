{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc92bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8355da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "accuracy_score,\n",
    "precision_score,\n",
    "recall_score,\n",
    "f1_score,\n",
    "fbeta_score,\n",
    "confusion_matrix,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import graphviz\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import itertools\n",
    "import torch.nn.init as init\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, KFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44026bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_test_dataset.csv')\n",
    "\n",
    "# Split the DataFrame into X_test and y_test\n",
    "X_test = df.iloc[:, :-1]  # Select all columns except the last one\n",
    "y_test = df.iloc[:, -1]   # Select the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37f7a948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.nn import init\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_hidden_layers, dropout_rate, activation, batch_norm):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc_input = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_hidden_layers)])\n",
    "        self.fc_output = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        if batch_norm:\n",
    "            self.batchnorms = nn.ModuleList([nn.BatchNorm1d(hidden_size) for _ in range(num_hidden_layers)])\n",
    "        self.batch_norm = batch_norm\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc_input(x)\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        for i, layer in enumerate(self.hidden_layers):\n",
    "            out = layer(out)\n",
    "            out = self.batchnorms[i](out) if self.batch_norm else out\n",
    "            out = self.activation(out)\n",
    "            out = self.dropout(out)\n",
    "\n",
    "        out = self.fc_output(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            init.constant_(m.bias, 0.0)\n",
    "\n",
    "df = pd.read_csv('sample_test_dataset.csv')\n",
    "\n",
    "# Split the DataFrame into X_test and y_test\n",
    "X_test = df.iloc[:, :-1]  # Select all columns except the last one\n",
    "y_test = df.iloc[:, -1]   # Select the last column\n",
    "# Load the pretrained model\n",
    "hidden_size = 64\n",
    "num_hidden_layers = 2\n",
    "batch_norm = False\n",
    "activation = 'relu'\n",
    "dropout_rate = 0.1\n",
    "input_size = X_test.shape[1]\n",
    "num_classes = 2\n",
    "pretrained_model = NeuralNetwork(input_size, hidden_size, num_classes, num_hidden_layers, dropout_rate, activation, batch_norm)\n",
    "pretrained_model.load_state_dict(torch.load(\"DNN_model.pt\"),strict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137177a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already loaded the pretrained model as \"pretrained_model\"\n",
    "\n",
    "pretrained_model.eval()  # Set the model in evaluation mode\n",
    "\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_inputs = test_inputs.to(device)\n",
    "        test_labels = test_labels.to(device)\n",
    "        test_outputs = pretrained_model(test_inputs)\n",
    "        test_loss = criterion(test_outputs, test_labels).item()\n",
    "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "        test_accuracy = torch.sum(test_predicted == test_labels).item() / len(test_labels)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "average_test_loss = sum(test_losses) / len(test_losses)\n",
    "average_test_accuracy = sum(test_accuracies) / len(test_accuracies)\n",
    "\n",
    "print(f\"Average Test Loss: {average_test_loss:.4f}\")\n",
    "print(f\"Average Test Accuracy: {average_test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the model in evaluation mode\n",
    "pretrained_model.eval()\n",
    "\n",
    "# Use the pretrained model for predictions or further training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "316a9d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd6f9911",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6c8f089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.16%\n",
      "Precision: 82.74%\n",
      "Recall: 86.36%\n",
      "F1 Score: 84.51%\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)\n",
    "test_dataset = CustomDataset(X_test_tensor, y_test_tensor)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = pretrained_model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_samples = 0\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_inputs = test_inputs.to(device)\n",
    "        test_labels = test_labels.to(device)\n",
    "        test_outputs = model(test_inputs)\n",
    "        test_loss += criterion(test_outputs, test_labels).item()\n",
    "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "        test_correct += torch.sum(test_predicted == test_labels).item()\n",
    "        test_samples += test_labels.size(0)\n",
    "        true_labels.extend(test_labels.tolist())\n",
    "        predicted_labels.extend(test_predicted.tolist())\n",
    "\n",
    "    test_loss /= test_samples\n",
    "    test_accuracy = test_correct / test_samples\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    if (tp + fp) != 0:\n",
    "        precision = tp / (tp + fp)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "input_size = (X_test.shape[1],)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "print(f'Precision: {precision * 100:.2f}%')\n",
    "print(f'Recall: {recall * 100:.2f}%')\n",
    "print(f'F1 Score: {f1 * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a252d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84549c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
